<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>image processing | Yifan Wang - ETH Zurich</title>
    <link>https://yifita.github.io/tags/image-processing/</link>
      <atom:link href="https://yifita.github.io/tags/image-processing/index.xml" rel="self" type="application/rss+xml" />
    <description>image processing</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 10 Sep 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yifita.github.io/img/icon-192.png</url>
      <title>image processing</title>
      <link>https://yifita.github.io/tags/image-processing/</link>
    </image>
    
    <item>
      <title>Blind Image Super-Resolution with Spatially Variant Degradations</title>
      <link>https://yifita.github.io/publication/variational_blindsr/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/variational_blindsr/</guid>
      <description>

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;overview_v3.png&#34; alt=&#34;overview&#34; /&gt;
In blind super-resolution, the degradation kernel k applied on the high resolution image to obtain the low resolution image $I_l$ is unknown. Our pipeline is duplicated for two different kernels (a) and (b): the degradation-aware generator ($\mathcal{F}_g$) computes a high resolution output according to the provided blur kernel k. We note that a NN $\mathcal{F}_k$ is used to map the kernels to a low dimensional representation. The two kernels will result in different high resolution estimates. The kernel (a) farther from the unknown original degradation leads to more artifacts. To detect this, we propose a kernel discriminator network ($\mathcal{F}_d$) predicting the error due to using the incorrect kernel. By taking advantage of these two networks, we can express kernel estimation as finding the blur kernel resulting in the least amount of errors and artifacts in the predicted high resolution image (See text for details). Photo Credits: Pixabay/pexels.com.&lt;/p&gt;

&lt;h2 id=&#34;results-screenshots-from-the-paper&#34;&gt;Results (screenshots from the paper)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;comparison.png&#34; alt=&#34;comparison&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Fully Progressive Approach to Single-Image Super-Resolution</title>
      <link>https://yifita.github.io/publication/prosr/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/prosr/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;teaser.png&#34; alt=&#34;teaser&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;prosr_benchmark.png&#34; alt=&#34;benchmark&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;MsLapSRN: Lai, Wei-Sheng, et al. &amp;ldquo;Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks.&amp;rdquo; arXiv preprint arXiv:1710.01992 (2017).&lt;/p&gt;

&lt;p&gt;EDSR, MDSR: Lim, Bee, et al. &amp;ldquo;Enhanced deep residual networks for single image super-resolution.&amp;rdquo; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops. Vol. 1. No. 2. 2017.&lt;/p&gt;

&lt;p&gt;RDN:Zhang, Yulun, et al. &amp;ldquo;Residual Dense Network for Image Super-Resolution.&amp;rdquo;  The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2018.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- ### Accompanying Video ###
(Best viewed in full-screen mode)

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/ON3XHnaDepE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 --&gt;

&lt;h3 id=&#34;featured-video&#34;&gt;Featured Video&lt;/h3&gt;

&lt;p&gt;It&amp;rsquo;s a pleasure to be featured in &amp;ldquo;&lt;a href=&#34;https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg&#34; target=&#34;_blank&#34;&gt;2 minute paper&lt;/a&gt;&amp;rdquo;, an amazing YouTube channel that introduces latest development of AI in a variety of applications.
Here&amp;rsquo;s the video that talks about our work.

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/HvH0b9K_Iro&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Single-Image Super-Resolution</title>
      <link>https://yifita.github.io/project/single-image-super-resolution/</link>
      <pubDate>Thu, 27 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/project/single-image-super-resolution/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
