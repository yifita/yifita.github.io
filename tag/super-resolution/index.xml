<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>super-resolution | Yifan Wang - ETH Zurich</title>
    <link>https://yifita.github.io/tag/super-resolution/</link>
      <atom:link href="https://yifita.github.io/tag/super-resolution/index.xml" rel="self" type="application/rss+xml" />
    <description>super-resolution</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 09 Mar 2022 16:30:00 +0000</lastBuildDate>
    <image>
      <url>https://yifita.github.io/media/icon_hu039e7a8dee100027504ac14a50a2ed32_26438_512x512_fill_lanczos_center_3.png</url>
      <title>super-resolution</title>
      <link>https://yifita.github.io/tag/super-resolution/</link>
    </image>
    
    <item>
      <title>“Neuralize” geometry processing pipeline</title>
      <link>https://yifita.github.io/talk/neuralize-geometry-processing-pipeline/</link>
      <pubDate>Wed, 09 Mar 2022 16:30:00 +0000</pubDate>
      <guid>https://yifita.github.io/talk/neuralize-geometry-processing-pipeline/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Video Super-Resolution Using An Artificial Neural Network</title>
      <link>https://yifita.github.io/publication/pro_sr_patent/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/pro_sr_patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Techniques for upscaling images generated with undetermined downscaling kernels</title>
      <link>https://yifita.github.io/publication/blindsr_patent/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/blindsr_patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Detail-Driven 3D Content Creation</title>
      <link>https://yifita.github.io/talk/detail-driven-3d-content-creation/</link>
      <pubDate>Wed, 03 Feb 2021 15:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/talk/detail-driven-3d-content-creation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pursuing high-resolution 3D Geometry with Deep Learning</title>
      <link>https://yifita.github.io/talk/pursuing-high-resolution-3d-geometry-with-deep-learning/</link>
      <pubDate>Thu, 11 Jun 2020 21:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/talk/pursuing-high-resolution-3d-geometry-with-deep-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Blind Image Super-Resolution with Spatially Variant Degradations</title>
      <link>https://yifita.github.io/publication/variational_blindsr/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/variational_blindsr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Patch-base progressive 3D Point Set Upsampling</title>
      <link>https://yifita.github.io/publication/3pu/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/3pu/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;teaser&#34; srcset=&#34;
               /publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_29e4c2e73cf14198b681c075e89cc5e3.webp 400w,
               /publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_ea18798aa6e56cbb4f141c14820fb2ed.webp 760w,
               /publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_29e4c2e73cf14198b681c075e89cc5e3.webp&#34;
               width=&#34;760&#34;
               height=&#34;148&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;center&gt;
$16\times$ upsampling from 625 points
&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_9edef7f108df2c1b3f9c6f0608ab5be6.webp 400w,
               /publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_3f99c9b0d0b641d18f7cdaef663270fa.webp 760w,
               /publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_9edef7f108df2c1b3f9c6f0608ab5be6.webp&#34;
               width=&#34;760&#34;
               height=&#34;343&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;center&gt;$16\times$ upsampling from 5000 points&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_c280fc3bd4125e84c9a2c64999f08963.webp 400w,
               /publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_f7cea573aa93dca15d613429aeaa3bd4.webp 760w,
               /publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_c280fc3bd4125e84c9a2c64999f08963.webp&#34;
               width=&#34;760&#34;
               height=&#34;531&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;center&gt;$16\times$ upsampling from scan data&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_c6d5e3840952a7f9e1ec97c0e98ad758.webp 400w,
               /publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_08d51235218398060491e310988f70e8.webp 760w,
               /publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_c6d5e3840952a7f9e1ec97c0e98ad758.webp&#34;
               width=&#34;760&#34;
               height=&#34;687&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;center&gt;$16\times$ upsampling from virtual scan data&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_14f5c7a1a4484ce97f369efc2acf65b3.webp 400w,
               /publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_f58525b23a69d89a8ff1b803b5c646af.webp 760w,
               /publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_14f5c7a1a4484ce97f369efc2acf65b3.webp&#34;
               width=&#34;704&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;PU-Net&lt;/em&gt;: L. Yu, X. Li, C.-W. Fu, D. Cohen-Or, and P.-A. Heng, &amp;ldquo;Pu-net: Point cloud upsampling network&amp;rdquo;, CVPR 2018&lt;/p&gt;
&lt;p&gt;&lt;em&gt;EC-Net&lt;/em&gt;: L. Yu, X. Li, C.-W. Fu, D. Cohen-Or, and P.-A. Heng, &amp;ldquo;Ec-net: an edge-aware point set consolidation network&amp;rdquo;,  ECCV 2018&lt;/p&gt;
&lt;p&gt;&lt;em&gt;EAR&lt;/em&gt;: H. Huang, S. Wu, M. Gong, D. Cohen-Or, U. Ascher, and H. Zhang, &amp;ldquo;Edge-aware point set resampling&amp;rdquo;, ACM ToG 2013&lt;/p&gt;
&lt;p&gt;&lt;em&gt;WLOP&lt;/em&gt;: H. Huang, D. Li, H. Zhang, U. Ascher, and D. Cohen-Or, &amp;ldquo;Consolidation of unorganized point clouds for surface reconstruction&amp;rdquo;, SIGGRAPH Asia 2009&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Fully Progressive Approach to Single-Image Super-Resolution</title>
      <link>https://yifita.github.io/publication/prosr/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/prosr/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;teaser&#34; srcset=&#34;
               /publication/prosr/teaser_hu7bc39c5843791f2e96e2bf4a6d0ee2c4_908466_e44849654acbd39102ae46abeff17938.webp 400w,
               /publication/prosr/teaser_hu7bc39c5843791f2e96e2bf4a6d0ee2c4_908466_793c5da1bb29de4a48c8814fed9e9b55.webp 760w,
               /publication/prosr/teaser_hu7bc39c5843791f2e96e2bf4a6d0ee2c4_908466_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/prosr/teaser_hu7bc39c5843791f2e96e2bf4a6d0ee2c4_908466_e44849654acbd39102ae46abeff17938.webp&#34;
               width=&#34;760&#34;
               height=&#34;213&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;benchmark&#34; srcset=&#34;
               /publication/prosr/prosr_benchmark_hu0c14cc2d175ff2dbd1dc10cd687365c1_129303_dcf64fa9555015f184b4bf576e7964ef.webp 400w,
               /publication/prosr/prosr_benchmark_hu0c14cc2d175ff2dbd1dc10cd687365c1_129303_d76b2bf232976c25a5dac77441dbf2e6.webp 760w,
               /publication/prosr/prosr_benchmark_hu0c14cc2d175ff2dbd1dc10cd687365c1_129303_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/prosr/prosr_benchmark_hu0c14cc2d175ff2dbd1dc10cd687365c1_129303_dcf64fa9555015f184b4bf576e7964ef.webp&#34;
               width=&#34;760&#34;
               height=&#34;154&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MsLapSRN: Lai, Wei-Sheng, et al. &amp;ldquo;Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks.&amp;rdquo; arXiv preprint arXiv:1710.01992 (2017).&lt;/p&gt;
&lt;p&gt;EDSR, MDSR: Lim, Bee, et al. &amp;ldquo;Enhanced deep residual networks for single image super-resolution.&amp;rdquo; The IEEE CVPR (CVPR) Workshops. Vol. 1. No. 2. 2017.&lt;/p&gt;
&lt;p&gt;RDN:Zhang, Yulun, et al. &amp;ldquo;Residual Dense Network for Image Super-Resolution.&amp;rdquo;  The IEEE CVPR (CVPR). 2018.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- ### Accompanying Video ###
(Best viewed in full-screen mode)

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ON3XHnaDepE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 --&gt;
&lt;h3 id=&#34;featured-video&#34;&gt;Featured Video&lt;/h3&gt;
&lt;p&gt;It&amp;rsquo;s a pleasure to be featured in &amp;ldquo;&lt;a href=&#34;https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2 minute paper&lt;/a&gt;&amp;rdquo;, an amazing YouTube channel that introduces latest development of AI in a variety of applications.
Here&amp;rsquo;s the video that talks about our work.

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/HvH0b9K_Iro&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Single-Image Super-Resolution</title>
      <link>https://yifita.github.io/project/single-image-super-resolution/</link>
      <pubDate>Thu, 27 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/project/single-image-super-resolution/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
