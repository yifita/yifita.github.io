[{"authors":["YifanWang"],"categories":null,"content":"I\u0026rsquo;m a fourth-year PhD student in the Interactive Geometry Lab at ETH Zurich supervised by Prof. Olga Sorkine-Hornung. My area of research lies in applying machine learning techniques, especially deep learning, to challenging image and geometry processing problems. During my PhD study, I have had the honour to work at the Advanced Innovation Center for Future Visual Entertainment (AICFVE) in Beijing Film Academy, the Imaging and Video group at Disney Research Zurich and the Creative Intelligence Lab at Adobe Research in Seattle.\nBorn and raised in Beijing, I went to Technische Universität München in Germany for study, where I obtained Bachelor of Science with distinction in Electrical Engineering and Information Technology.\nAfterwards I went to ETH Zurich in Switzerland, where I completed with the Master program Robotics, Systems and Control with distinction.\n","date":1607558400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607558400,"objectID":"f91bdc3427753dc0f7ea9e5496fbbd2c","permalink":"https://yifita.github.io/authors/yifanwang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yifanwang/","section":"authors","summary":"I\u0026rsquo;m a fourth-year PhD student in the Interactive Geometry Lab at ETH Zurich supervised by Prof. Olga Sorkine-Hornung. My area of research lies in applying machine learning techniques, especially deep learning, to challenging image and geometry processing problems. During my PhD study, I have had the honour to work at the Advanced Innovation Center for Future Visual Entertainment (AICFVE) in Beijing Film Academy, the Imaging and Video group at Disney Research Zurich and the Creative Intelligence Lab at Adobe Research in Seattle.","tags":null,"title":"Yifan Wang","type":"authors"},{"authors":["Yifan Wang","ShihaoWu","CengizOeztireli","OlgaSorkine"],"categories":null,"content":"We propose a hybrid neural surface representation with implicit functions and iso-points. The representation leads to accurate and robust surface reconstruction from imperfect data. The on-the-fly conversion with efficient iso-points extraction allows us to augment existing optimization pipelines in a variety of ways. In the first row, geometry-aware regularizers are incorporated to reconstruct a surface from a noisy point cloud; in the second row, geometric details are preserved in multi-view reconstruction via feature-aware sampling; in the last row, iso-points serve as a 3D prior to improve the topological accuracy of the reconstructed surface\nWe efficiently extract a dense, uniformly distributed set of iso-points as an explicit representation for a neural implicit surface. Since the extraction is fast, iso-points can be integrated back into the optimization as a 3D geometric prior, enhancing the optimization.\n","date":1607558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607558400,"objectID":"15cd37f60d23cdc2872794b443b4b736","permalink":"https://yifita.github.io/publication/iso_points/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/publication/iso_points/","section":"publication","summary":"Inter-dependent explicit representations for optimizing neural implicit surfaces","tags":["geometry processing","surface reconstruction","deep learning"],"title":"Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations","type":"publication"},{"authors":["Yifan Wang","NoamAigerman","VovaKim","SidChaudhuri","OlgaSorkine"],"categories":null,"content":"We can warp an arbitrary input shape to match the grob structure of an arbitrary target shape, while preserving all the local geometric details. The input and target shape is not required to have dense correspondences, the same topology, or even the same representation form (e.g. points, mesh and 2D image). The key of our method is reducing the degrees of freedom of the deformation space by extending the traditional cage-based deformation technique.\nApplication 1 - Shape synthesis We use our method to learn a meaningful deformation space over a collection of shapes within the same category, and then use random pairs of source and target shapes to synthesize plausible variations of artist-generated assets. Application 2 - Deformation transfer We first learn the cage deformation space for a template source shape (top left) with known pose and body shape variations. Then, we annotate predefined landmarks on new characters in neutral poses (left column, rows 2-4). At test time, given novel target poses (top row, green) without known correspondences to the template, we transfer their poses to the other characters (blue).\nDue to the agnostic nature of cage-deformations to the underlying shape, we are able to seamlessly combine machine learning and traditional geometry processing to generalize to never-observed characters, even if the novel source and target characters are morphologically very different from the both the template source.\nTalk    This is the talk I\u0026rsquo;ll be giving virtually for CVPR2020.\n","date":1584144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584144000,"objectID":"56b48b416e5155ffbcd3738365bf7ef5","permalink":"https://yifita.github.io/publication/deep_cage/","publishdate":"2020-03-14T00:00:00Z","relpermalink":"/publication/deep_cage/","section":"publication","summary":"We propose a novel learnable representation for detail-preserving shape deformation extending a traditional cage-based deformation technique. We demonstrate the utility of our method for synthesizing shape variations and deformation transfer.","tags":["deformation","shape modeling","deep learning","3D"],"title":"Neural Cages for Detail-Preserving 3D Deformations","type":"publication"},{"authors":["Victor Cornillère","AbdelazizDjelouah","Yifan Wang","OlgaSorkine","ChristopherSchroers"],"categories":null,"content":"Overview In blind super-resolution, the degradation kernel k applied on the high resolution image to obtain the low resolution image $I_l$ is unknown. Our pipeline is duplicated for two different kernels (a) and (b): the degradation-aware generator ($\\mathcal{F}_g$) computes a high resolution output according to the provided blur kernel k. We note that a NN $\\mathcal{F}_k$ is used to map the kernels to a low dimensional representation. The two kernels will result in different high resolution estimates. The kernel (a) farther from the unknown original degradation leads to more artifacts. To detect this, we propose a kernel discriminator network ($\\mathcal{F}_d$) predicting the error due to using the incorrect kernel. By taking advantage of these two networks, we can express kernel estimation as finding the blur kernel resulting in the least amount of errors and artifacts in the predicted high resolution image (See text for details). Photo Credits: Pixabay/pexels.com.\nResults (screenshots from the paper) ","date":1568073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568073600,"objectID":"5644e904519719091fad771448f41cd1","permalink":"https://yifita.github.io/publication/variational_blindsr/","publishdate":"2019-09-10T00:00:00Z","relpermalink":"/publication/variational_blindsr/","section":"publication","summary":"We propose a novel approach for single image super-resolution to simultaneously predict high resolution images and the degradation kernels.","tags":["image processing","super-resolution","deep learning","image"],"title":"Blind Image Super-Resolution with Spatially Variant Degradations","type":"publication"},{"authors":["Yifan Wang","Felice Serena","ShihaoWu","CengizOeztireli","OlgaSorkine"],"categories":null,"content":"Shape Synthesis We can synthesize shapes from multiple 2D images. This process is not constrained by topology changes. Point Cloud Filering Using DSS we can directly apply image-based filters to a point cloud to achieve various geometric effect. Point Cloud Denoising We create state-of-the-art point cloud denoising results by marrying our differential renderer with the famous image-to-image translation deep learning framework Pix2Pix. Accompanying Video   Acknowledgement We would like to thank Federico Danieli for the insightful discussion, Philipp Herholz for the timely feedack, Romann Weber for the video voice-over and Derek Liu for the help during the rebuttal. This work was supported in part by gifts from Adobe, Facebook and Snap, Inc.\n","date":1564358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564358400,"objectID":"f9cfe2faadb93867e711425faa964bd3","permalink":"https://yifita.github.io/publication/dss/","publishdate":"2019-07-29T00:00:00Z","relpermalink":"/publication/dss/","section":"publication","summary":"We propose a high-fidelity differentiable renderer for point clouds. We demonstrate how the proposed technique can be used to leverage contemporary deep neural networks to achieve state-of-the-art results in challenging geometry processing tasks.","tags":["geometry processing","point cloud","deep learning","rendering","3D"],"title":"Differentiable Surface Splatting for Point-based Geometry Processing","type":"publication"},{"authors":null,"categories":null,"content":"","date":1561766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561766400,"objectID":"80bb9a74f5dcab69055a451248709b85","permalink":"https://yifita.github.io/project/neural-shape/","publishdate":"2019-06-29T00:00:00Z","relpermalink":"/project/neural-shape/","section":"project","summary":"Representing and generating shapes using neural networks","tags":["Deep Learning","shape modeling","3D"],"title":"Neural Shapes","type":"project"},{"authors":["Yifan Wang","ShihaoWu","HuiHuang","DanielCohenor","OlgaSorkine"],"categories":null,"content":"Results    References PU-Net: L. Yu, X. Li, C.-W. Fu, D. Cohen-Or, and P.-A. Heng, \u0026ldquo;Pu-net: Point cloud upsampling network\u0026rdquo;, CVPR 2018\nEC-Net: L. Yu, X. Li, C.-W. Fu, D. Cohen-Or, and P.-A. Heng, \u0026ldquo;Ec-net: an edge-aware point set consolidation network\u0026rdquo;, ECCV 2018\nEAR: H. Huang, S. Wu, M. Gong, D. Cohen-Or, U. Ascher, and H. Zhang, \u0026ldquo;Edge-aware point set resampling\u0026rdquo;, ACM ToG 2013\nWLOP: H. Huang, D. Li, H. Zhang, U. Ascher, and D. Cohen-Or, \u0026ldquo;Consolidation of unorganized point clouds for surface reconstruction\u0026rdquo;, SIGGRAPH Asia 2009\n","date":1561334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561334400,"objectID":"ad39d116047628dce95aceeb6af0c9ce","permalink":"https://yifita.github.io/publication/3pu/","publishdate":"2019-06-24T00:00:00Z","relpermalink":"/publication/3pu/","section":"publication","summary":"We present a detail-driven deep neural network for point set upsampling. A high-resolution point set is essential for point-based rendering and surface reconstruction. Inspired by the recent success of neural image super-resolution techniques, we progressively train a cascade of patch-based upsampling networks on different levels of detail end-to-end. We propose a series of architectural design contributions that lead to a substantial performance boost. The effect of each technical contribution is demonstrated in an ablation study. Qualitative and quantitative experiments show that our method significantly outperforms the state-of-the-art learning-based and optimazation-based approaches, both in terms of handling low-resolution inputs and revealing high-fidelity details.","tags":["point cloud","super-resolution","deep learning","geometry processing","3D"],"title":"Patch-base progressive 3D Point Set Upsampling","type":"publication"},{"authors":null,"categories":null,"content":"","date":1524787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524787200,"objectID":"45275d342533c1f0633acc26122b3285","permalink":"https://yifita.github.io/project/point-geometry/","publishdate":"2018-04-27T00:00:00Z","relpermalink":"/project/point-geometry/","section":"project","summary":"Making use of this extremely flexible yet unstructured form of shape represenation.","tags":["Deep Learning","geometry processing","point cloud","3D"],"title":"Point-based geometry processing","type":"project"},{"authors":["Yifan Wang","FedericoPerazzi","BrianMcWilliams","AlexanderHornung","OlgaSorkine","ChristopherSchroers"],"categories":null,"content":"Results  MsLapSRN: Lai, Wei-Sheng, et al. \u0026ldquo;Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks.\u0026rdquo; arXiv preprint arXiv:1710.01992 (2017).\nEDSR, MDSR: Lim, Bee, et al. \u0026ldquo;Enhanced deep residual networks for single image super-resolution.\u0026rdquo; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops. Vol. 1. No. 2. 2017.\nRDN:Zhang, Yulun, et al. \u0026ldquo;Residual Dense Network for Image Super-Resolution.\u0026rdquo; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2018.\n Featured Video It\u0026rsquo;s a pleasure to be featured in \u0026ldquo;2 minute paper\u0026rdquo;, an amazing YouTube channel that introduces latest development of AI in a variety of applications. Here\u0026rsquo;s the video that talks about our work.   ","date":1523836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1523836800,"objectID":"2375f889a32d2d73dc112f3f464731d5","permalink":"https://yifita.github.io/publication/prosr/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/prosr/","section":"publication","summary":"We set a new benchmark for single-image super-resolution by exploiting progressiveness both in architecture and training. The proposed multi-scale models, **ProSR** and **ProSRGan**, improve the reconstruction quality in terms of PSNR and visual quality respectively. ProSR is one of the winning teams.","tags":["super-resolution","image processing","deep learning","image"],"title":"A Fully Progressive Approach to Single-Image Super-Resolution","type":"publication"},{"authors":null,"categories":null,"content":"","date":1493251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493251200,"objectID":"105797dda5efbb8aea73eb8475651802","permalink":"https://yifita.github.io/project/single-image-super-resolution/","publishdate":"2017-04-27T00:00:00Z","relpermalink":"/project/single-image-super-resolution/","section":"project","summary":"Pushing the limit of \"zoom-in\"s.","tags":["image processing","deep learning","super-resolution","2D"],"title":"Single-Image Super-Resolution","type":"project"},{"authors":["Yifan Wang","JieSong","Limin Wang","Luc Van Gool","OtmarHilliges"],"categories":null,"content":"Network Architecture ","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"766a3c831d4b11b535c5476c69fcdb9f","permalink":"https://yifita.github.io/publication/action_srcnn/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/publication/action_srcnn/","section":"publication","summary":"We propose a new deep architecture by incorporating object/human detection results into the framework for action recognition, called two-stream semantic region based CNNs (SR-CNNs). We perform experiments on UCF101 dataset and demonstrate its superior performance to the original two-stream CNNs. ","tags":["action recognition","video"],"title":"Two-Stream SR-CNNs for Action Recognition in Videos","type":"publication"}]