<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SidChaudhuri | Yifan Wang - ETH Zurich</title>
    <link>https://yifita.github.io/authors/sidchaudhuri/</link>
      <atom:link href="https://yifita.github.io/authors/sidchaudhuri/index.xml" rel="self" type="application/rss+xml" />
    <description>SidChaudhuri</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 14 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yifita.github.io/media/icon_hu039e7a8dee100027504ac14a50a2ed32_26438_512x512_fill_lanczos_center_3.png</url>
      <title>SidChaudhuri</title>
      <link>https://yifita.github.io/authors/sidchaudhuri/</link>
    </image>
    
    <item>
      <title>Neural Cages for Detail-Preserving 3D Deformations</title>
      <link>https://yifita.github.io/publication/deep_cage/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/deep_cage/</guid>
      <description>&lt;h3 id=&#34;we-can-warp-an-arbitrary-input-shape-to-match-the-grob-structure-of-an-arbitrary-target-shape-while-__preserving-all-the-local-geometric-details__-the-input-and-target-shape-is-not-required-to-have-dense-correspondences-the-same-topology-or-even-the-same-representation-form-eg-points-mesh-and-2d-image&#34;&gt;We can warp an arbitrary input shape to match the grob structure of an arbitrary target shape, while &lt;strong&gt;preserving all the local geometric details&lt;/strong&gt;. The input and target shape is not required to have dense correspondences, the same topology, or even the same representation form (e.g. points, mesh and 2D image).&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overview&#34; srcset=&#34;
               /publication/deep_cage/overview_huce44a8d917894b13664a2dd0ef2adf56_275854_9f9ea1433ebeb41a46aaa0460a37652e.webp 400w,
               /publication/deep_cage/overview_huce44a8d917894b13664a2dd0ef2adf56_275854_142e69f16b1fdbc45400f24343727424.webp 760w,
               /publication/deep_cage/overview_huce44a8d917894b13664a2dd0ef2adf56_275854_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/deep_cage/overview_huce44a8d917894b13664a2dd0ef2adf56_275854_9f9ea1433ebeb41a46aaa0460a37652e.webp&#34;
               width=&#34;600&#34;
               height=&#34;277&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

The key of our method is reducing the degrees of freedom of the deformation space by extending the traditional cage-based deformation technique.&lt;/p&gt;
&lt;h2 id=&#34;application-1---shape-synthesis&#34;&gt;Application 1 - Shape synthesis&lt;/h2&gt;
&lt;p&gt;We use our method to
learn a meaningful deformation space over a collection of
shapes within the same category, and then use random pairs
of source and target shapes to synthesize plausible variations
of artist-generated assets.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;comparison&#34; srcset=&#34;
               /publication/deep_cage/comparison_hud82a3f8c98c56d6c297225582a652c0c_618165_d73ba3bca739c64ff17ec484b237faf7.webp 400w,
               /publication/deep_cage/comparison_hud82a3f8c98c56d6c297225582a652c0c_618165_817c254dceb92a998b36de8941f5d6f6.webp 760w,
               /publication/deep_cage/comparison_hud82a3f8c98c56d6c297225582a652c0c_618165_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/deep_cage/comparison_hud82a3f8c98c56d6c297225582a652c0c_618165_d73ba3bca739c64ff17ec484b237faf7.webp&#34;
               width=&#34;760&#34;
               height=&#34;542&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;application-2---deformation-transfer&#34;&gt;Application 2 - Deformation transfer&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;dt&#34; srcset=&#34;
               /publication/deep_cage/deformation_transfer_hucf5be2d167f530b3c6c4ccf6ffd30f6f_1897426_8ab11b080197451e9276541d3f1edf23.webp 400w,
               /publication/deep_cage/deformation_transfer_hucf5be2d167f530b3c6c4ccf6ffd30f6f_1897426_910abcbd9aa43db9a91718c3ca3586f1.webp 760w,
               /publication/deep_cage/deformation_transfer_hucf5be2d167f530b3c6c4ccf6ffd30f6f_1897426_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/deep_cage/deformation_transfer_hucf5be2d167f530b3c6c4ccf6ffd30f6f_1897426_8ab11b080197451e9276541d3f1edf23.webp&#34;
               width=&#34;760&#34;
               height=&#34;529&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

We first learn the cage deformation space
for a template source shape (top left) with known pose and body shape
variations. Then, we annotate predefined landmarks on new characters
in neutral poses (left column, rows 2-4). At test time, given novel target
poses (top row, green) without known correspondences to the template, we
transfer their poses to the other characters (blue).&lt;/p&gt;
&lt;p&gt;Due to the agnostic nature of cage-deformations to
the underlying shape, we are able to seamlessly combine
machine learning and traditional geometry processing to
generalize to never-observed characters, even if the novel source and target characters are morphologically very different from the both the template source.&lt;/p&gt;
&lt;h2 id=&#34;talk&#34;&gt;Talk&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/UZLAj2xTojY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
