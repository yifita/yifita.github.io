<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ShihaoWu | Yifan Wang - ETH Zurich</title>
    <link>https://yifita.github.io/authors/shihaowu/</link>
      <atom:link href="https://yifita.github.io/authors/shihaowu/index.xml" rel="self" type="application/rss+xml" />
    <description>ShihaoWu</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 10 Mar 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yifita.github.io/media/icon_hu039e7a8dee100027504ac14a50a2ed32_26438_512x512_fill_lanczos_center_3.png</url>
      <title>ShihaoWu</title>
      <link>https://yifita.github.io/authors/shihaowu/</link>
    </image>
    
    <item>
      <title>Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations</title>
      <link>https://yifita.github.io/publication/iso_points/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/iso_points/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/3myC2_BIGcI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;teaser&#34; srcset=&#34;
               /publication/iso_points/teaser_hu80b79292638aae25df499a8d7dc77d01_777796_1ef04da86b868f3dcaf33c1d6935ac73.webp 400w,
               /publication/iso_points/teaser_hu80b79292638aae25df499a8d7dc77d01_777796_60132638dd7dc1c68cfdecd882805afa.webp 760w,
               /publication/iso_points/teaser_hu80b79292638aae25df499a8d7dc77d01_777796_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/iso_points/teaser_hu80b79292638aae25df499a8d7dc77d01_777796_1ef04da86b868f3dcaf33c1d6935ac73.webp&#34;
               width=&#34;739&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

We propose a hybrid neural surface representation with implicit
functions and iso-points. The representation leads to accurate and robust
surface reconstruction from imperfect data. The on-the-fly conversion with
efficient iso-points extraction allows us to augment existing optimization
pipelines in a variety of ways. In the first row, geometry-aware regularizers
are incorporated to reconstruct a surface from a noisy point cloud; in the
second row, geometric details are preserved in multi-view reconstruction
via feature-aware sampling; in the last row, iso-points serve as a 3D prior
to improve the topological accuracy of the reconstructed surface&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overview&#34; srcset=&#34;
               /publication/iso_points/overview_hu0c4236b94b99942f60443bad6e5b1405_288338_1f9f2b7f0ce1cc6998cd5a9351a409f6.webp 400w,
               /publication/iso_points/overview_hu0c4236b94b99942f60443bad6e5b1405_288338_aa3a6cf9dca09e79bc68c3da5a703fe4.webp 760w,
               /publication/iso_points/overview_hu0c4236b94b99942f60443bad6e5b1405_288338_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/iso_points/overview_hu0c4236b94b99942f60443bad6e5b1405_288338_1f9f2b7f0ce1cc6998cd5a9351a409f6.webp&#34;
               width=&#34;760&#34;
               height=&#34;387&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

We efficiently extract a dense, uniformly distributed set of iso-points as an explicit representation for a neural implicit surface. Since the extraction is fast, iso-points can be integrated back into the optimization as a 3D geometric prior, enhancing the optimization.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Techniques for performing point-based inverse rendering</title>
      <link>https://yifita.github.io/publication/dss_patent/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/dss_patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differentiable Surface Splatting for Point-based Geometry Processing</title>
      <link>https://yifita.github.io/publication/dss/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/dss/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;teaser&#34; srcset=&#34;
               /publication/dss/teaser_hu0603bb4b795549b646695bb3eace70fe_787383_38dd0ddb9c6fbb25603783af242ca2d9.webp 400w,
               /publication/dss/teaser_hu0603bb4b795549b646695bb3eace70fe_787383_a421a81f6e6e0c9b9ab0f81dc08a44d0.webp 760w,
               /publication/dss/teaser_hu0603bb4b795549b646695bb3eace70fe_787383_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/dss/teaser_hu0603bb4b795549b646695bb3eace70fe_787383_38dd0ddb9c6fbb25603783af242ca2d9.webp&#34;
               width=&#34;760&#34;
               height=&#34;172&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;shape-synthesis&#34;&gt;Shape Synthesis&lt;/h3&gt;
&lt;p&gt;We can synthesize shapes from multiple 2D images. This process is not constrained by topology changes.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;synthesis&#34; srcset=&#34;
               /publication/dss/yoga_hud75168a24873154fc3315cd4622e3aa1_3068741_8e740b09b020bb7c257e65816084662d.webp 400w,
               /publication/dss/yoga_hud75168a24873154fc3315cd4622e3aa1_3068741_6bf1c254bf0f6d9df1deb1c1e39ad25f.webp 760w,
               /publication/dss/yoga_hud75168a24873154fc3315cd4622e3aa1_3068741_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/dss/yoga_hud75168a24873154fc3315cd4622e3aa1_3068741_8e740b09b020bb7c257e65816084662d.webp&#34;
               width=&#34;760&#34;
               height=&#34;559&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;point-cloud-filering&#34;&gt;Point Cloud Filering&lt;/h3&gt;
&lt;p&gt;Using DSS we can directly apply image-based filters to a point cloud to achieve various geometric effect.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;filtering&#34; srcset=&#34;
               /publication/dss/DSSfilter_hu2b42d738bd54101b04a2a9934a042558_2336149_5e371b9ffb432d11101f3380b62a1255.webp 400w,
               /publication/dss/DSSfilter_hu2b42d738bd54101b04a2a9934a042558_2336149_2e2ad411b5e91f6dd48923955132de67.webp 760w,
               /publication/dss/DSSfilter_hu2b42d738bd54101b04a2a9934a042558_2336149_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/dss/DSSfilter_hu2b42d738bd54101b04a2a9934a042558_2336149_5e371b9ffb432d11101f3380b62a1255.webp&#34;
               width=&#34;760&#34;
               height=&#34;564&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;point-cloud-denoising&#34;&gt;Point Cloud Denoising&lt;/h3&gt;
&lt;p&gt;We create state-of-the-art point cloud denoising results by marrying our differential renderer with the famous image-to-image translation deep learning framework &lt;em&gt;Pix2Pix&lt;/em&gt;.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Denoising&#34; srcset=&#34;
               /publication/dss/armadillo_2_all_hue32edefd6be881a28491b18f438ad233_2527235_ca6e5f96231589480cd8fe9580ae5c9f.webp 400w,
               /publication/dss/armadillo_2_all_hue32edefd6be881a28491b18f438ad233_2527235_3543a0456a3eddd40ddfc712b19ab0ff.webp 760w,
               /publication/dss/armadillo_2_all_hue32edefd6be881a28491b18f438ad233_2527235_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/dss/armadillo_2_all_hue32edefd6be881a28491b18f438ad233_2527235_ca6e5f96231589480cd8fe9580ae5c9f.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;accompanying-video&#34;&gt;Accompanying Video&lt;/h3&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Q8iTkmIky0o&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;We would like to thank Federico Danieli for the insightful discussion, Philipp Herholz for the timely feedack, Romann Weber for the video voice-over and Derek Liu for the help during the rebuttal.
This work was supported in part by gifts from Adobe, Facebook and Snap, Inc.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Patch-base progressive 3D Point Set Upsampling</title>
      <link>https://yifita.github.io/publication/3pu/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://yifita.github.io/publication/3pu/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;teaser&#34; srcset=&#34;
               /publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_29e4c2e73cf14198b681c075e89cc5e3.webp 400w,
               /publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_ea18798aa6e56cbb4f141c14820fb2ed.webp 760w,
               /publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/teaser_hue941d5737ff9a65a92341b6d94789b13_1958401_29e4c2e73cf14198b681c075e89cc5e3.webp&#34;
               width=&#34;760&#34;
               height=&#34;148&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;center&gt;
$16\times$ upsampling from 625 points
&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_9edef7f108df2c1b3f9c6f0608ab5be6.webp 400w,
               /publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_3f99c9b0d0b641d18f7cdaef663270fa.webp 760w,
               /publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/figure_sparse_hud2ea52a596ae36c36eb01f40e00c846e_1836455_9edef7f108df2c1b3f9c6f0608ab5be6.webp&#34;
               width=&#34;760&#34;
               height=&#34;343&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;center&gt;$16\times$ upsampling from 5000 points&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_c280fc3bd4125e84c9a2c64999f08963.webp 400w,
               /publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_f7cea573aa93dca15d613429aeaa3bd4.webp 760w,
               /publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/figure_dense_hu014ad1967466bfe0de5a18b8abf9e18d_3850114_c280fc3bd4125e84c9a2c64999f08963.webp&#34;
               width=&#34;760&#34;
               height=&#34;531&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;center&gt;$16\times$ upsampling from scan data&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_c6d5e3840952a7f9e1ec97c0e98ad758.webp 400w,
               /publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_08d51235218398060491e310988f70e8.webp 760w,
               /publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/real_scan_hu291df38f9bd4033062d7137c94f34fb5_4162448_c6d5e3840952a7f9e1ec97c0e98ad758.webp&#34;
               width=&#34;760&#34;
               height=&#34;687&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;center&gt;$16\times$ upsampling from virtual scan data&lt;/center&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_14f5c7a1a4484ce97f369efc2acf65b3.webp 400w,
               /publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_f58525b23a69d89a8ff1b803b5c646af.webp 760w,
               /publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yifita.github.io/publication/3pu/scan_hud8ec081405baf5878204f29fd86bddd9_1766035_14f5c7a1a4484ce97f369efc2acf65b3.webp&#34;
               width=&#34;704&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;PU-Net&lt;/em&gt;: L. Yu, X. Li, C.-W. Fu, D. Cohen-Or, and P.-A. Heng, &amp;ldquo;Pu-net: Point cloud upsampling network&amp;rdquo;, CVPR 2018&lt;/p&gt;
&lt;p&gt;&lt;em&gt;EC-Net&lt;/em&gt;: L. Yu, X. Li, C.-W. Fu, D. Cohen-Or, and P.-A. Heng, &amp;ldquo;Ec-net: an edge-aware point set consolidation network&amp;rdquo;,  ECCV 2018&lt;/p&gt;
&lt;p&gt;&lt;em&gt;EAR&lt;/em&gt;: H. Huang, S. Wu, M. Gong, D. Cohen-Or, U. Ascher, and H. Zhang, &amp;ldquo;Edge-aware point set resampling&amp;rdquo;, ACM ToG 2013&lt;/p&gt;
&lt;p&gt;&lt;em&gt;WLOP&lt;/em&gt;: H. Huang, D. Li, H. Zhang, U. Ascher, and D. Cohen-Or, &amp;ldquo;Consolidation of unorganized point clouds for surface reconstruction&amp;rdquo;, SIGGRAPH Asia 2009&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
